

### Q1. What is the relationship between depth and error in neural networks?
**Shallow Networks:**
  - Lower training and testing errors.
  - Easier to optimize but cannot learn complex patterns

**Deep Networks:**
  - Higher capacity to learn complex patterns.
  - Risk of higher training error due to optimization challenges like vanishing gradients.


### Q2. How does the vanishing gradient problem affect training, and what are its solutions?
- Gradients become very small during backpropagation, causing earlier layers to learn very slowly.
- ReLU or Leaky ReLU activation functions.
- Proper weight initialization (e.g., Xavier, He).
- Batch normalization 
- residual connections (ResNet).


### Q3. What are underfitting and overfitting, and how are they addressed?
**Underfitting:**
  - Model too simple to capture patterns.
  - Addressed by increasing model complexity, training longer, or using better features

**Overfitting:**
    - Model fits noise in training data.
    - Addressed by using regularization, increasing data, or monitoring validation performance

### Q12. What causes underfitting, and how can it be solved?
- Model complexity is too low.
- Insufficient training time or data.
- Excessive regularization.

- Increase model complexity (layers, neurons).
- Train for more epochs.
- Provide more meaningful features.
- Lower regularization penalties (L1/L2).

### Q13. What are the symptoms and causes of overfitting?
- Low training error but high testing error.
- Model performs well on training data but poorly on new data.

- Too many layers or neurons.
- Insufficient training data.
- Lack of regularization.
- Over-training.

### Q4. What are L1 and L2 regularization, and when are they used?
- Penalty weights
- L1  Encourages sparsity (some weights = 0).  
- L2 Shrinks all weights towards smaller values.
- L1 Use Case Feature selection.                
- L2 Use Case General overfitting reduction.


### Q5. What are saddle points, and why are they challenging for optimization?
- Points where gradients are zero but are neither minima nor maxima.
- Trap optimization algorithms, slowing convergence
- Use algorithms like Adam or momentum to escape saddle points.


### Momentum and GD
- help with escaping Local Minima
- Smoother Updates
- accelerates convergence by smoothing out oscillations in the optimization process.
- is an enhancement to Gradient Descent

### Q15. What is the difference between convex and non-convex functions, and how do they affect optimization?
- **Convex Functions:**
    - Bowl-shaped with a single global minimum.
    - Easier to optimize.
- **Non-Convex Functions:**
    - Contain multiple minima, maxima, and saddle points.

### Q20. Why does gradient descent not guarantee reaching the global minimum?
- **Local Minima and Saddle Points:**
- **Non-Convex Loss Functions:**
- Results depend on the initial starting point.

### Q6. Explain gradient descent and its types.
- Iteratively adjusts parameters to minimize the loss function.
1. **Batch GD:** Uses the entire dataset per update; slow but stable.
2. **Mini-Batch GD:** Balances speed and stability by using small batches.
3. **Stochastic GD (SGD):** Updates on individual samples; noisy but fast.

### Q7. What is the role of learning rate, and how can it be managed?
- Determines step size in parameter updates.
- Too high: Overshoots the optimal solution.
- Too low: Converges very slowly.
- Use adaptive methods like Adam or learning rate decay.






### Q8. How do ResNets address optimization challenges in deep networks?
- Skip connections allow layers to learn residual mappings (\(H(x) = F(x) + x\)).
- Eases gradient flow and prevents vanishing gradients.
- Enables training of very deep networks with fewer optimization issues.




### Q9. What is the difference between parameters and hyper-parameters in neural networks?

Learned during training.    | Set before training.
Weights, biases.            | Learning rate, number of layers.
Adjusted via gradient descent. | Tuned via grid/random search.


### Q10. What are common regularization techniques, and why are they used?
- Reduce overfitting by discouraging the model from learning noise.
1. **L1/L2 Regularization:** Penalize large weights.
2. **Dropout:** Randomly disables neurons during training.
3. **Early Stopping:** Stops training when validation performance deteriorates.


### Q18. How does dropout work as a regularization technique?

- Randomly drops neurons during training, disabling them temporarily.
- Prevents overfitting by reducing neuron co-adaptation.
- Encourages the network to learn robust features.


